# Characterising-Toxicity-in-Language-Models

## Goal
This project aims to characterize from a linguistic viewpoint what formulations and structures might cause generative large language models (LLMs) to generate toxic content.
